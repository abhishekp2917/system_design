*   When to incorporate caching in a system ?

>>  (1) Frequent Access to the Same Data:

        Caching reduces the load on the database or backend by serving the frequently access data from the cache.

    (2) Expensive Computations:

        If generating data is computationally expensive, caching the results eliminates redundant computations.
    
    (3) Global Accessibility:

        If users from different geographic regions access your application,a distributed caching solution, like a CDN, 
        reduces latency by serving data from nodes closest to the user.
        
    (4) Read-Heavy Workloads:

        If a system has a high ratio of read operations compared to writes, caching reduces read load on the 
        primary data source.

________________________________________________________________________________________________________________________

*   What are various caching techniques in terms of scope ?

>>  (1) Local Caching:
        
        Local caching refers to storing cached data within the same system or server where the application runs.

                                _________          _____________
                                |       |          |           |
                                |   A   |          | Server-1  |
                                |   P   |--------->|           |                   
        _____________           |   I   |          |___________|--------|      
        |           |           |       |          |  cache-1  |        |      _____________
        |  client   |---------->|   G   |          |___________|        |----->|           |
        |___________|           |   A   |                                      | Database  |
                                |   T   |                                      |           |               
                                |   E   |          _____________        |----->|___________|
                                |   W   |          |           |        |       
                                |   A   |          | Server-2  |        |
                                |   Y   |--------->|           |        |
                                |       |          |___________|--------|
                                |_______|          |  cache-2  |
                                                   |___________|

        Key Characteristics:
            
            - The cache is isolated to a single instance of the application.    
            - Typically stored in the application’s memory or local disk.
            - Fastest access because no network communication is needed.

        Advantages:
        
            - Low Latency: Since the data is stored on the same machine, retrieval is extremely fast.
            - Simplicity: Easy to implement and requires minimal infrastructure.
            - Cost-Effective: No additional infrastructure for caching is needed.

        Disadvantages:
            
            - Not Scalable: Storage capacity of the server is limited.
            - No Synchronization: Cache is not shared, so multiple application instances can have inconsistent cache states.

    (2) Distributed Caching:
        
        Distributed caching stores cached data across multiple nodes in a distributed system, making the cache 
        accessible to all applications in the system.

        
                                _________          _____________               ___________________________________
                                |       |          |           |               |         Cache Cluster           |                                    
                                |   A   |          |           |               | _____________     _____________ |                            
                                |   P   |--------->|  Server-1 |               | |           |     |           | |    
        _____________           |   I   |          |           |--------|      | |           |     |           | |
        |           |           |       |          |           |        |      | |  cache-1  |     |  cache-1  | |      _____________
        |  client   |---------->|   G   |          |___________|        |      | |           |     |           | |      |           |
        |___________|           |   A   |                               |----->| |___________|     |___________| |      | Database  | 
                                |   T   |                                      |        _____________            |----->|           |                         
                                |   E   |          _____________        |----->|        |           |            |      |___________|
                                |   W   |          |           |        |      |        |           |            |      
                                |   A   |          |           |        |      |        |  cache-1  |            |
                                |   Y   |--------->|  Server-2 |        |      |        |           |            |
                                |       |          |           |--------|      |        |___________|            |
                                |_______|          |           |               |                                 |
                                                   |___________|               |_________________________________|
        Key Characteristics:
            
            - The cache is shared across the network, allowing multiple instances of an application to access it.
            - Data is distributed among multiple cache nodes, often using consistent hashing for placement.
        
        Advantages:
            
            Scalable: Additional nodes can be added to handle increased cache size or traffic.
            Fault Tolerant: If one node fails, others can take over.
            Global Cache State: Provides a consistent view of cached data across all application instances.

        Disadvantages:
            
            Network Overhead: Slightly higher latency due to network communication.
            Complexity: Requires additional setup and maintenance for cache clusters.
            Data Consistency: Managing synchronization and replication can be challenging.

________________________________________________________________________________________________________________________

*   What are various cache eviction policies ?

>>  Cache eviction policies determine how data is removed from the cache when the cache reaches its maximum capacity. 

    (1) Least Recently Used (LRU):
        
        Removes the least recently accessed items first.

        How It Works: 
        
            - Keeps track of usage order. 
            - When space is needed, the item that hasn’t been accessed for the longest time is evicted.

    (2) Least Frequently Used (LFU):
        
        Removes items that are accessed the least number of times.
        
        How It Works: 
        
            - Maintains a counter for each cached item. 
            - Items with the lowest access frequency are evicted first.

    (3) Time-To-Live (TTL):

        Items are evicted after a predefined time period, regardless of access frequency or recency.

        How It Works: 
        
            - Each cached item is assigned a TTL. 
            - When the TTL expires, the item is removed.
            - Might evict useful data prematurely, leading to cache misses.

________________________________________________________________________________________________________________________

*   What are various cache read and write policies ? 

>>  (1) Write-Through Caching:

        How It Works:
            
            - Data is written to the cache and the underlying storage simultaneously.
            - Application writes data to the cache.
            - Cache takes the responsibility and immediately writes data to the backend storage.
            - Acknowledgment is sent back to the application only after both writes are successful.

        Advantages:
            
            - Data consistency is guaranteed between the cache and storage.
        
        Disadvantages:

            - Write operations are slower due to dual writes (cache + storage).
            - High latency for write-heavy applications.
        
        When to Use:
            
            - Use in systems where data consistency is critical, e.g., banking systems.
            - Ideal for read-heavy workloads.


    (2) Write-Back Caching:
        
        How It Works:
            
            - Data is written to the cache only. The backend storage is updated asynchronously.
            - Application writes data to the cache.
            - Cache sends an acknowledgment immediately.
            - Cache writes the data to the backend storage asynchronously or in batches.
        
        Advantages:
            
            - Faster write operations since data is acknowledged after being cached.
            - Reduces backend storage load during peak times.

        Disadvantages:
            
            - Risk of data loss if the cache fails before syncing with the storage.
            - Increased complexity in ensuring consistency.

        When to Use:
            
            - Use in write-heavy applications where performance is more critical than strict consistency  e.g., 
              analytics or logging systems.
    
    (3) Write-Around Caching:
        
        How It Works:
            
            - Data is written directly to the backend storage, bypassing the cache.
            - Application writes data to the backend storage directly.
            - The old data in the cache may be invalidate but won't be updated with new one.
            - Cache is updated only on a read miss.
        
        Advantages:
            
            - Reduces cache churn for infrequently accessed data.
            - Good for systems where write operations dominate but reads happen occasionally or in bursts.

        Disadvantages:
            
            - Potential for cache misses on subsequent reads.

        When to Use:
            
            - Use in systems with write-dominant workloads where data is rarely read immediately after being written.

    (4) Read-Through Caching:
            
        How It Works:
            
            - On a cache miss, the cache fetches the data from the backend storage, updates itself, and then serves 
              the request.
            - Application reads data from the cache.
            - If data is present in the cache (cache hit), it is returned directly.
            - If data is not in the cache (cache miss), cache fetches the data from the storage, updates itself, and 
              returns to the application.

        Advantages:
            
            - Automatically populates the cache with frequently accessed data.
        
        Disadvantages:
            
            - Initial cache misses incur higher latency due to fetching data from storage.
            - Cache may become a bottleneck under heavy read loads.

        When to Use:
            
            - Use in read-heavy applications where the same data is accessed frequently, e.g., CDNs.

    (5) Read-Aside Caching:

        How It works:

            - Application reads data from the cache.
            - If the data is present (cache hit), it is returned directly.
            - If the data is not present (cache miss), the application fetches the data from the database, stores it 
              in the cache, and returns it to the user.

        Advantages:
        
            - The application always queries the database on a cache miss, ensuring that the database remains the 
              source of truth.

        Disadvantages:

            - The application must handle caching logic, including cache population, invalidation, and updates.
            - High latency in case of a cache miss compare to Read-Through Caching.

        When to Use:

            - When you need fine control, work with unpredictable access patterns, or are integrating caching into a 
              legacy system.
________________________________________________________________________________________________________________________
