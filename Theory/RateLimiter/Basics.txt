*   What is Rate Limiter ?

>>  A rate limiter is used to control the rate at which requests are processed, ensuring that a system is not overwhelmed 
    by excessive requests. 
    
    Rate limiting reduces the possibility of Denial-of-Service (DoS) attacks by placing restrictions on the maximum number 
    of requests that can be served in a given amount of time.

________________________________________________________________________________________________________________________

*   What are various types of Rate Limiting ?

>>  (1) IP-based Rate Limiting:

        - The number of requests that can be sent from a single IP address in a specified amount of time is limited by 
          IP-based rate limitation (e.g., 10 requests per minute). 
          
        - Restricting the amount of traffic from a single IP address is frequently used to stop abuses like bots and 
          Denial-of-Service attacks.

        Advantages:
            
            - It’s simple to implement at both the network and application level.
            
            - If someone is trying to flood the system with requests, limiting their IP can prevent this.
        
        Disadvantages:
            
            - Attackers can use techniques like VPNs, proxy servers, or even botnets to spoof different IPs and get 
              around the limit.
            
            - If multiple users share the same IP address (like in a corporate network), a legitimate user could get 
              blocked if someone else on the same network exceeds the limit.

    (2) Server-based Rate Limiting:

        - The number of requests that can be sent to a particular server in a predetermined period of time 
          (e.g., 100 requests per second) is controlled by server-based rate restriction.

        Advantages:
            
            - Helps protect the server from being overwhelmed, especially during peak usage.
        
        Disadvantages:
            
            - Attackers can spread their requests across multiple servers, staying within the rate limit for each server 
              while still overwhelming the system overall..
            
            - If the limit is too low or the server is under heavy load, even legitimate users might face delays or blocks.


    (3) Geography-based Rate Limiting:

        - Geography-based rate limiting restricts traffic based on the geographic location of the IP address. 
        
        - It’s useful for blocking malicious requests that originate from certain regions (for example, countries known 
          for high levels of cyber attacks), or for complying with regional laws and regulations.

        Advantages:

            - If you know certain regions are the source of a lot of bad traffic (e.g., spam, hacking attempts), you can 
              limit requests from those areas.
            
            - Helps comply with local data protection laws or restrictions on content in certain countries.
        
        Disadvantages:
            
            - Attackers can use VPNs or proxy servers to disguise their actual location and get around geography-based limits.
            
            - Users traveling or accessing services via international servers (like employees using VPNs) might get 
              blocked if they’re in a region that's restricted.

________________________________________________________________________________________________________________________

*   What are various Rate limiting algorithms ?

>>  Following are the widely used Rate limiting algorithms:

        (1) Token Bucket
        (2) Leaky Bucket 
        (3) Fixed Window Counter
        (4) Sliding Window Log
        (5) Sliding Window Counter

________________________________________________________________________________________________________________________

*   What are various Rate limiting architecture being followed in the industry ?

>>  (1) Gateway-Level Rate Limiter:

        How It Works:
          
            (a) API Gateway Interception:

                - An API gateway or reverse proxy (e.g., NGINX) acts as the entry point for all requests to the backend services.
            
                - The gateway enforces rate limits before forwarding requests.
          
            (b) Request Identification:

                - Requests are identified using API keys, IP addresses, or user accounts.
          
                - Rate-limiting data (e.g., counters or tokens) is maintained by the gateway in-memory.
        
            (c) Rate Limiting Enforcement:

                - If the request count for a client exceeds the limit, the gateway denies the request with a proper error 
                  response (e.g., HTTP 429).
            
                - Otherwise, the request is forwarded to the backend.
        
        Advantages:

            (a) Centralized Control: 
            
                - Simple to manage rate limiting for all backend services at one place.
            
            (b) Scalability: 
            
                - Gateways are designed to handle high traffic and can be scaled horizontally.

        Disadvantages:

            (a) Bottleneck Potential: 
            
                - The gateway can become a single point of failure or performance bottleneck.

    (2) Individual Service Rate Limiter:
        
        How It Works:
          
           (a) Request Arrival:
                
                - A client sends a request directly to the individual service or through an intermediary 
                  (e.g., an API gateway).

            (b) Rate-Limiting Logic:
                
                - Each individual service handles the rate limiting logic independently. 
                                
                - The service tracks the client's request count or token availability in memory or a local database.
                
                - It applies a rate-limiting algorithm (e.g., Fixed Window, Token Bucket, Sliding Window).
            
            (c) Decision:
                
                - If the client is within the defined rate limits, the service processes the request.
                
                - Otherwise, the service returns an error response (e.g., HTTP 429 Too Many Requests).
        
        Advantages:
            
            (a) Granular Control:

                - Rate limits can be tailored to the specific needs of each service, ensuring more precise 
                  resource protection.
            
            (b) Scalability:

                - The service can operate independently, avoiding dependency on external components like 
                  centralized rate limiters.

            (c) Low Latency:

                - Decisions are made directly at the service level, reducing latency.

            (d) Fault Tolerant:

                - If a service goes down, it won't impact rate limiting of other services in the system. 

        Disadvantages:
            
            (a) Complexity in Distributed Systems:

                - Each service must implement its own rate-limiting logic, leading to duplication of effort and 
                  maintenance challenges.

            (b) Performance Overhead:

                - implementing rate-limiting data locally can impact on service performance, especially in high-traffic 
                  scenarios.
    
    (3) Distributed Rate Limiter:
        
        How It Works:
            
            (a) Centralized Server:

                - A shared datastore (e.g., Redis, Memcached) maintains counters, tokens, or timestamps for each client 
                  or API key.
                
                - The datastore ensures that all rate-limiting decisions are consistent across multiple nodes.
    
            (b) Distributed Servers:

                - Each server in the distributed system queries or updates the shared datastore whenever a request is received.
                
                - The rate limiting algorithm (e.g., Token Bucket, Sliding Window) is implemented in the centralized store.
    
            (c) Rate Limiting Decision:

                - If the request count for a given key (e.g., API key, user ID) within the specified time window exceeds 
                  the allowed limit, the request is rejected (HTTP 429 - Too Many Requests).
                
                - Otherwise, the request is allowed.
        
        Advantages:
    
            (a) Scalability: 
                
                - Handles high traffic volumes by adding more nodes to the rate limiting system.

            (b) Centralized Store:

                - A centralized place for managing the rate limiting request. 
    
        Disadvantages:
    
            (a) Latency: 
            
                - Each rate-limiting check involves a network call to the datastore, adding latency.
    
            (b) Datastore Dependency: 
            
                - The centralized store can become a single point of failure if not managed properly.
    
            (c) Complexity: 
            
                - Requires robust mechanisms for synchronization and consistency.
            
________________________________________________________________________________________________________________________

*   When to apply rate limiting and what not to ?

>>  When to Apply Rate Limiting:

        (1) High-Traffic or Resource-Intensive APIs:

            - APIs that perform computationally expensive operations or access rate-sensitive resources (e.g., database queries, 
              file processing) should be limited to protect system performance.

        (2) APIs with Business Constraints:

            - APIs tied to subscription plans or licensing agreements often have usage quotas (e.g., free vs. premium plans) 
              should be rate limited.
        
        (3) APIs Prone to Abuse:

            - APIs that are susceptible to misuse, such as login endpoints (to prevent brute-force attacks) or search endpoints 
              (to avoid scraping), should be rate-limited.

    When Not to Apply Rate Limiting:

        (1) Internal APIs:

            - APIs used exclusively for internal communication between microservices or system components generally do 
              not require rate limiting unless there is a risk of cascading failures.
        
        (2) Idempotent or Read-Heavy APIs:

            - Lightweight, read-only APIs that do not stress resources significantly might not need rate limiting.

        (3) Critical System Operations:

            - APIs critical for system health (e.g., heartbeat checks, health probes) should not be rate-limited as 
              they can disrupt system monitoring or failover mechanisms.

        (4) Low-Traffic APIs:

            - APIs with predictable, low traffic may not need rate limiting unless they have other vulnerabilities.

________________________________________________________________________________________________________________________