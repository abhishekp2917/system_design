*   Explain Token Bucket rate limiting algorithm in detail ?

>>  How It Works:

        (1) Tokens in a Bucket:

            - A bucket holds tokens which represents permission to process one request.
           
            - The bucket has a fixed capacity (e.g., 100 tokens).

        (2) Adding Tokens:

            - Tokens are added to the bucket at a constant rate (e.g., 10 tokens per second).
            
            - If the bucket is full, new tokens are discarded until space is available.
        
        (3) Processing Requests:

            - When a request arrives, the algorithm checks if there’s at least one token in the bucket.
            
            - If a token is available, it is removed, and the request is processed.
            
            - If no tokens are available, the request is denied or delayed.

        (4) Handling Bursts:

            - If the bucket has accumulated tokens (because of lower traffic earlier), it can allow a burst of requests 
              up to the bucket’s capacity.

            - Once tokens are depleted, the algorithm throttles further requests to the token replenishment rate.

    Example:

        - Bucket Capacity   : 10 tokens
        
        - Token Refill Rate : 2 tokens/second

        - At time T0, the bucket is full with 10 tokens.
        
        - At T1 (1 second later), 2 tokens are added, reaching the maximum of 10 tokens (if none were used).
        
        - If a burst of 7 requests arrives, all are processed, leaving 3 tokens.
        
        - If another burst of 5 requests arrives immediately after, only 3 are processed, and the remaining 2 are denied.
    
    Advantages:

        (1) Simplicity:

            - Easy to understand and implement.
            
            - Works efficiently in distributed systems.

        (2) Burst Handling:

            - Supports short bursts of traffic, as tokens accumulate during idle periods.
            
            - Provides flexibility for scenarios with variable traffic patterns.

        (3) Efficient Resource Usage:

            - Prevents overloading the system by throttling requests when necessary.

        (4) Fine Control:

            - Allows independent control of burst size (bucket capacity) and steady traffic rate (token refill rate).

    Disadvantages:

        (1) Overhead:

            - Requires maintaining state for each bucket (e.g., tokens and last refill time) which can be memory-intensive 
              in large-scale systems.

        (2) Limited Precision:

            - It may not prevent large bursts over longer timeframes if multiple buckets accumulate tokens.

        (3) Fairness:

            - If multiple clients share a bucket, it does not guarantee fairness, as a single client could deplete tokens 
              rapidly.

________________________________________________________________________________________________________________________

*   Explain Leaky Bucket rate limiting algorithm in detail ?

>>  How It Works:

        - The leaky bucket algorithm works by envisioning a bucket with a small hole at the bottom.

        (1) Initialization:

            - Define a bucket capacity B (the maximum number of requests the bucket can hold).
            
            - Set a leakage rate R (number of requests processed per unit time).

        (2) Adding Requests:

            - Incoming requests are treated as water being poured into the bucket which has a fixed capacity (e.g., 10 requests).
        
        (3) Fixed Processing Rate:

            - Water leaks out of the bucket at a constant rate, simulating the system processing requests at a steady 
              pace (e.g., 1 request/second).
            
            - The rate of leakage is constant, regardless of how much requests are in the bucket.

        (4) Overflow Handling:

            - If the bucket is full, then any additional incoming request will be denied.

    Example:

        - Bucket Capacity   : 5 requests
        
        - Leakage Rate      : 2 requests/second

        - At time T0, the bucket is empty.
        
        - At T1, 4 requests arrive and the bucket now holds 4 requests.
        
        - At T2, another 3 requests arrive. But since, the bucket can only hold 1 more, so 2 requests overflow and are denied.
        
        - Over time, the system processes 2 requests/second, reducing the bucket's load.
    
    Advantages:

        (1) Simplicity:

            - Easy to understand and integrate into systems.
        
        (2) Smooth Traffic Flow:

            - Ensures a consistent and predictable processing rate, avoiding sudden bursts or spikes.
        
        (3) Effective Resource Control:

            - Prevents overloading the system by dropping excess requests.
    
    Disadvantages:
        
        (1) No Burst Support:

            - Does not allow for bursts of traffic, as requests are processed at a fixed rate, even if the system has 
              idle capacity.

________________________________________________________________________________________________________________________

*   Explain Fixed Window Counter rate limiting algorithm in detail ?

>>  How It Works:

        (1) Time Division:

            - Time is divided into fixed intervals (e.g., 1 second, 1 minute).
            
            - Each interval is treated as a "window."
        
        (2) Request Counting:

            - For each window, a counter is initialized to zero at the start.
            
            - Each incoming request increments the counter for the current window.
        
        (3) Rate Limiting:

            - If the counter exceeds a predefined limit during the current window, further requests are denied.
            
            - At the start of the next window, the counter resets to zero.

    Example:
        
        - Window size   : 1 second each

        - Limit         : 10 requests per second    
        
        - At time T0 (start of a new window), counter is initialized to 0.

        - Requests arrive and are processed.

        - After 10 requests, the counter reaches the limit, denying any further request in current window.
            
        - At T1 (next second), counter resets to 0, and requests are accepted again.

    Advantages:

        (1) Simplicity:

            - Easy to implement and understand.
        
            - Minimal overhead, as it requires only a counter for each fixed window.

        (2) Low Memory Usage:

            - Maintains just one counter per user or API key, making it memory-efficient for simple rate-limiting needs.

        (3) Predictable Behavior:

            - The algorithm provides clear and consistent rate limits within each fixed window.

    Disadvantages:

        (1) Boundary Problems (Burstiness):

            - The algorithm allows "bursts" of traffic at the boundary of two windows.
            
            - If the limit is 10 requests/second, a user could send 10 requests at the very end of one second and another 
              10 requests at the start of the next, effectively sending 20 requests in a short period.
        
        (2) No Granularity Within the Window:

            - Cannot distribute requests smoothly across the window.
            
            - All requests could arrive at the start of the window, potentially causing load spikes.

________________________________________________________________________________________________________________________

*   Explain Sliding Window Counter rate limiting algorithm in detail ?

>>  How It Works:

        (1) Dynamic Time Windows:

            - Instead of dividing time into fixed intervals, the sliding window moves dynamically based on the time of 
              incoming requests.
            
            - Each request contributes to a time-based record, and the system continuously calculates the count of requests 
              within a rolling time window.
        
        (2) Request Timestamps:

            - For each incoming request, the algorithm stores a timestamp in a data structure (e.g., a queue or a hashmap).
            
            - Old requests (which are yet to be processed) that fall outside the sliding window are removed from this data 
              structure.

        (3) Rate Limiting:

            - The system checks if the number of requests within the sliding window exceeds the limit.
            
            - If not, the request is allowed else the request is denied or delayed.

    Example:

        - Sliding Window size: 1 second

        - Limit: 5 requests per second
        
        - At T0 = 0.1s, request arrives and is allowed. (Queue: [0.1])
    
        - At T1 = 0.2s, Request arrives and is allowed. (Queue: [0.1, 0.2])

        - At T2 = 0.5s, Request arrives and is allowed. (Queue: [0.1, 0.2, 0.5])

        - At T3 = 0.9s, Request arrives and is allowed. (Queue: [0.1, 0.2, 0.5, 0.9])

        - At T4 = 1.0s, Request arrives and is allowed. (Queue: [0.1, 0.2, 0.5, 0.9, 1.0])

        - At T5 = 1.1s, Request arrives and is allowed. 
        
        - Since, request at 0.1s is no longer in the 1 second window, it will be removed. (Queue: [0.2, 0.5, 0.9, 1.0, 1.1])
    
    Advantages:
        
        (1) Smooth Traffic Control:

            - Eliminates the burstiness issue seen in the fixed window counter.
            
            - Distributes requests more evenly across time.

        (2) Fairness:

            - Accurately enforces limits regardless of when requests arrive.
            
    Disadvantages:

        (1) Complexity:

            - More complex to implement than the fixed window counter.

        (2) Higher Memory Usage:

            - Requires maintaining a data structure to store timestamps for all recent requests.
            
            - Memory requirements grow with the rate limit and window size.
            
        (3) Computational Overhead:

            - Continuous pruning of old timestamps and real-time recalculations can increase computational cost.

________________________________________________________________________________________________________________________